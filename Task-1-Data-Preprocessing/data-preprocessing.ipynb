{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18858,"sourceType":"datasetVersion","datasetId":13996}],"dockerImageVersionId":31259,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e803a09c-b260-42cf-96b6-015f8850a6d5","cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n\n# This helps identify incorrect data types\nprint(df.dtypes)\n\n# The 'TotalCharges' column is stored as object because of empty spaces\n\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n\n\ndf.drop('customerID', axis=1, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e89966d7-4d23-4f8f-a3fd-2da0f2bc07f1","cell_type":"code","source":"# Checking how many missing values are present in each column\nprint(df.isnull().sum())\n\n# median is a safer choice than mean for filling missing values\ntotal_charges_median = df['TotalCharges'].median()\ndf['TotalCharges'] = df['TotalCharges'].fillna(total_charges_median)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ace85abe-03d2-4dd7-abc7-20a160dd503b","cell_type":"code","source":"# Function to handle outliers using the IQR method\n# Instead of deleting rows, extreme values are capped to reduce their impact\n\ndef handle_outliers(df, column):\n    Q1 = df[column].quantile(0.25)\n    Q3 = df[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    \n\n    df[column] = np.where(df[column] > upper_bound, upper_bound,\n                 np.where(df[column] < lower_bound, lower_bound, df[column]))\n    return df\n\n\n# Applying outlier handling to numerical columns\n\n# These columns are more likely to have skewed values\n\nfor col in ['tenure', 'MonthlyCharges', 'TotalCharges']:\n    df = handle_outliers(df, col)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bf0ecb46-6e00-4516-a16b-461dcb5be842","cell_type":"code","source":"# double checking\nprint(df.columns)\n\n# Selecting categorical columns that have multiple categories\n# These columns need one-hot encoding\n\nmulti_category_cols = [\n    'gender', 'MultipleLines', 'InternetService', 'OnlineSecurity', \n    'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', \n    'StreamingMovies', 'Contract', 'PaymentMethod'\n]\n\n# Converting categorical variables into numerical format using one-hot encoding\n# drop_first=True ........ because this avoids creating unncecessary dummy columns\n\ndf = pd.get_dummies(df, columns=multi_category_cols, drop_first=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b3a80665-2f45-4bcf-a6dd-97d447c461b6","cell_type":"code","source":"# Saving the cleaned dataset\n\ndf.to_csv('Telco_Churn_Cleaned.csv', index=False)\nprint(\"Data Preprocessing Complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}